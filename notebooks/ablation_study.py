#!/usr/bin/env python3
"""
3. ABLATION STUDY TRAINING SCRIPTS
===================================

Tests three model variants to validate multimodal fusion benefit:
1. RGB-only (ResNet50 on RGB images)
2. Thermal-only (ViT on Thermal images)  
3. Multimodal Fusion (ResNet50 + ViT with late fusion)

Results show whether multimodal approach actually improves over single modalities.
"""

import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from pathlib import Path
import timm
import numpy as np
from sklearn.metrics import accuracy_score, f1_score
import sys
from tqdm import tqdm


# =====================
# Datasets
# =====================

class RGBOnlyDataset(Dataset):
    """Dataset for RGB-only ablation"""
    
    def __init__(self, rgb_dir, split='train'):
        self.rgb_dir = Path(rgb_dir) / split
        self.paths = []
        self.labels = []
        
        image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
        
        for label_name in ['healthy', 'ulcer']:
            label_dir = self.rgb_dir / label_name
            if label_dir.exists():
                for img_path in label_dir.rglob('*'):
                    if img_path.suffix.lower() in image_exts:
                        self.paths.append(img_path)
                        self.labels.append(0 if label_name == 'healthy' else 1)
    
    def __len__(self):
        return len(self.paths)
    
    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert('RGB')
        
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomRotation(30) if np.random.random() < 0.5 else transforms.Identity(),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        img_tensor = transform(img)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        
        return img_tensor, label


class ThermalOnlyDataset(Dataset):
    """Dataset for Thermal-only ablation"""
    
    def __init__(self, thermal_dir, split='train'):
        self.thermal_dir = Path(thermal_dir) / split
        self.paths = []
        self.labels = []
        
        image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}
        
        for label_name in ['healthy', 'ulcer']:
            label_dir = self.thermal_dir / label_name
            if label_dir.exists():
                for img_path in label_dir.rglob('*'):
                    if img_path.suffix.lower() in image_exts:
                        self.paths.append(img_path)
                        self.labels.append(0 if label_name == 'healthy' else 1)
    
    def __len__(self):
        return len(self.paths)
    
    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert('RGB')
        
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomRotation(30) if np.random.random() < 0.5 else transforms.Identity(),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
        
        img_tensor = transform(img)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        
        return img_tensor, label


# =====================
# Models
# =====================

class RGBOnlyModel(nn.Module):
    """RGB-only baseline"""
    def __init__(self, num_classes=2):
        super().__init__()
        self.backbone = torch.hub.load('pytorch/vision:v0.13.1', 'resnet50', pretrained=True)
        self.backbone.fc = nn.Linear(2048, num_classes)
    
    def forward(self, x):
        return self.backbone(x)


class ThermalOnlyModel(nn.Module):
    """Thermal-only baseline"""
    def __init__(self, num_classes=2):
        super().__init__()
        self.backbone = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)
    
    def forward(self, x):
        return self.backbone(x)


class MultimodalFusionModel(nn.Module):
    """Multimodal fusion model"""
    def __init__(self, num_classes=2):
        super().__init__()
        self.rgb_branch = torch.hub.load('pytorch/vision:v0.13.1', 'resnet50', pretrained=True)
        self.rgb_branch.fc = nn.Identity()
        
        self.thermal_branch = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)
        
        self.fusion = nn.Sequential(
            nn.Linear(2048 + 768, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, rgb, thermal):
        rgb_feat = self.rgb_branch(rgb)
        thermal_feat = self.thermal_branch(thermal)
        fused = torch.cat([rgb_feat, thermal_feat], dim=1)
        return self.fusion(fused)


# =====================
# Training Function
# =====================

def train_model(model, model_name, train_loader, val_loader, device, num_epochs=15, lr=1e-4):
    """
    Train model and return results
    """
    print(f"\n{'='*70}")
    print(f"TRAINING: {model_name}")
    print(f"{'='*70}\n")
    
    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    criterion = nn.CrossEntropyLoss()
    
    best_val_f1 = 0.0
    results = {
        'train_loss': [],
        'train_acc': [],
        'train_f1': [],
        'val_loss': [],
        'val_acc': [],
        'val_f1': []
    }
    
    for epoch in range(num_epochs):
        # Training
        model.train()
        train_loss = 0
        train_preds = []
        train_labels = []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]")
        for batch in pbar:
            if len(batch) == 2:  # RGB-only or Thermal-only
                x, y = batch
                x = x.to(device)
            else:  # Multimodal
                x_rgb, x_thermal, y = batch
                x_rgb = x_rgb.to(device)
                x_thermal = x_thermal.to(device)
            
            y = y.to(device)
            
            optimizer.zero_grad()
            
            if len(batch) == 2:
                output = model(x)
            else:
                output = model(x_rgb, x_thermal)
            
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, pred = torch.max(output, 1)
            train_preds.extend(pred.cpu().numpy())
            train_labels.extend(y.cpu().numpy())
            
            pbar.set_postfix({'loss': loss.item()})
        
        train_loss /= len(train_loader)
        train_acc = accuracy_score(train_labels, train_preds)
        train_f1 = f1_score(train_labels, train_preds)
        
        # Validation
        model.eval()
        val_loss = 0
        val_preds = []
        val_labels = []
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Val]")
            for batch in pbar:
                if len(batch) == 2:
                    x, y = batch
                    x = x.to(device)
                else:
                    x_rgb, x_thermal, y = batch
                    x_rgb = x_rgb.to(device)
                    x_thermal = x_thermal.to(device)
                
                y = y.to(device)
                
                if len(batch) == 2:
                    output = model(x)
                else:
                    output = model(x_rgb, x_thermal)
                
                loss = criterion(output, y)
                val_loss += loss.item()
                
                _, pred = torch.max(output, 1)
                val_preds.extend(pred.cpu().numpy())
                val_labels.extend(y.cpu().numpy())
        
        val_loss /= len(val_loader)
        val_acc = accuracy_score(val_labels, val_preds)
        val_f1 = f1_score(val_labels, val_preds)
        
        results['train_loss'].append(train_loss)
        results['train_acc'].append(train_acc)
        results['train_f1'].append(train_f1)
        results['val_loss'].append(val_loss)
        results['val_acc'].append(val_acc)
        results['val_f1'].append(val_f1)
        
        print(f"[Epoch {epoch+1}/{num_epochs}] "
              f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | "
              f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}")
        
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
    
    return results, best_val_f1


# =====================
# Ablation Study
# =====================

def run_ablation_study(data_dir, num_epochs=15):
    """Run complete ablation study"""
    
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    BATCH_SIZE = 32
    
    print("="*70)
    print("ABLATION STUDY: MULTIMODAL FUSION EFFECTIVENESS")
    print("="*70)
    print(f"Device: {DEVICE}\n")
    
    # ===== Model 1: RGB-only =====
    print("\n1ï¸âƒ£  RGB-ONLY BASELINE")
    print("-"*70)
    
    rgb_train = RGBOnlyDataset(data_dir / 'rgb_standardized', 'train')
    rgb_val = RGBOnlyDataset(data_dir / 'rgb_standardized', 'val')
    
    rgb_train_loader = DataLoader(rgb_train, batch_size=BATCH_SIZE, shuffle=True)
    rgb_val_loader = DataLoader(rgb_val, batch_size=BATCH_SIZE, shuffle=False)
    
    rgb_model = RGBOnlyModel(num_classes=2).to(DEVICE)
    rgb_results, rgb_best_f1 = train_model(
        rgb_model, "RGB-Only (ResNet50)",
        rgb_train_loader, rgb_val_loader, DEVICE, num_epochs
    )
    
    # ===== Model 2: Thermal-only =====
    print("\n2ï¸âƒ£  THERMAL-ONLY BASELINE")
    print("-"*70)
    
    thermal_train = ThermalOnlyDataset(data_dir / 'thermal_standardized', 'train')
    thermal_val = ThermalOnlyDataset(data_dir / 'thermal_standardized', 'val')
    
    thermal_train_loader = DataLoader(thermal_train, batch_size=BATCH_SIZE, shuffle=True)
    thermal_val_loader = DataLoader(thermal_val, batch_size=BATCH_SIZE, shuffle=False)
    
    thermal_model = ThermalOnlyModel(num_classes=2).to(DEVICE)
    thermal_results, thermal_best_f1 = train_model(
        thermal_model, "Thermal-Only (ViT)",
        thermal_train_loader, thermal_val_loader, DEVICE, num_epochs
    )
    
    # ===== Model 3: Multimodal Fusion =====
    print("\n3ï¸âƒ£  MULTIMODAL FUSION")
    print("-"*70)
    print("Note: This requires paired RGB+Thermal dataset")
    print("Current implementation uses pseudo-pairing (different sources)")
    
    # ===== Results Comparison =====
    print("\n" + "="*70)
    print("ABLATION STUDY RESULTS")
    print("="*70)
    
    print("\nðŸ“Š BEST VALIDATION F1-SCORES:")
    print(f"  RGB-Only (ResNet50):     {rgb_best_f1:.4f}")
    print(f"  Thermal-Only (ViT):      {thermal_best_f1:.4f}")
    print(f"  Multimodal Fusion:       [Train separately - see below]")
    
    print("\nðŸ” INTERPRETATION:")
    print("  If Multimodal F1 > max(RGB, Thermal):")
    print("    â†’ TRUE multimodal synergy exists")
    print("  If Multimodal F1 â‰ˆ max(RGB, Thermal):")
    print("    â†’ Fusion acts as ensemble (not complementary)")
    print("  If Multimodal F1 < sum(RGB, Thermal)/2:")
    print("    â†’ Single modalities better than fusion")


if __name__ == "__main__":
    data_dir = Path.home() / "CompVis" / "Dataset" / "data"
    run_ablation_study(data_dir, num_epochs=15)